{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juan pablo aguirre\n"
     ]
    }
   ],
   "source": [
    "NAME = \"juan pablo aguirre\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e0e533da5815559c0bf6121cbae94175",
     "grade": false,
     "grade_id": "cell-7fa9ef9f0e824f8d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# SparkSQL\n",
    "\n",
    "In this notebook, we introduce SparkSQL, Spark's interface for working with structured data. From Spark 2.0 and forward, this is the preferred way of implementing Spark code, as it contains all of the latest optimisations.\n",
    "\n",
    "PySpark benefits a lot from SparkSQL, as there is performance parity between Scala, Java, Python and R interfaces for Spark which use the same optimizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae5307e7bf7fafde6df9f802b9b7a528",
     "grade": false,
     "grade_id": "cell-6e5d231a205820d5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Prerequisites\n",
    "\n",
    "Before running Spark code, we need to start a SparkSession instance. The following block will be common to every notebook so you can run your code.\n",
    "\n",
    "While your SparkSession is running, you can hit `http://localhost:4040` to get an overview of your Spark local cluster and all operations ongoing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbe887d38fff8342d47e41abcd97211a",
     "grade": false,
     "grade_id": "cell-5be3741301fa4113",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x7f7b644fdd90>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://e48659c20014:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local</code></dd>\n              <dt>AppName</dt>\n                <dd><code>lecture-lyon2</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf().setAppName('lecture-lyon2').setMaster('local')\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3dc4cbc9925a07f92a9d0150ddac48c2",
     "grade": false,
     "grade_id": "cell-7d0185de085b6093",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "\n    <div class=\"bk-root\">\n        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n        <span id=\"1002\">Loading BokehJS ...</span>\n    </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  var JS_MIME_TYPE = 'application/javascript';\n  var HTML_MIME_TYPE = 'text/html';\n  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  var CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    var script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    var cell = handle.cell;\n\n    var id = cell.output_area._bokeh_element_id;\n    var server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd, {\n        iopub: {\n          output: function(msg) {\n            var id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    var output_area = handle.output_area;\n    var output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n      return\n    }\n\n    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      var bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      var script_attrs = bk_div.children[0].attributes;\n      for (var i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      var toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import other important libraries\n",
    "\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import DataFrameReader\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bokeh.plotting import figure, show, ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10a41f7082f75a43843018815e6b7d25",
     "grade": false,
     "grade_id": "cell-a37b40688b026b9a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Part A - On to DataFrames / Datasets\n",
    "\n",
    "A `Dataset` is a distributed collection of data which provides the benefits of RDDs (strong typing, ability to use lambda functions) with the benefits of SparkSQL's optimized execution engine.\n",
    "\n",
    "A `DataFrame` is a `Dataset` organized into named columns. It is conceptually equivalent to a table in a relational database, or a data frame in Python/R. Conceptually, a `DataFrame` is a `Dataset` of `Row`s.\n",
    "\n",
    "As with RDDs, applications can create DataFrames from an existing RDD, a Hive table or from Spark data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa12bb7ce18076896fa86bfa294d7691",
     "grade": false,
     "grade_id": "cell-e5336c5bf4eae8ef",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Question\n",
    "\n",
    "Recall from the previous assignment how we used two tables on students : one for students to grades, another one for students to gender. Let's create a function which takes a RDD of Row and a schema as arguments and generates the corresponding DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a60e45e3c213939dc899b77a569322ea",
     "grade": false,
     "grade_id": "cell-33e39dc1e3d93fe9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def create_dataframe(spark, rdd, schema):\n",
    "    \"\"\"\n",
    "    Generate a DataFrame from a RDD of Rows and a schema.\n",
    "    We assume the RDD is correctly formatted, no need to check for anything.\n",
    "    \"\"\"\n",
    "    return spark.createDataFrame(rdd, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "2 points\n",
    "\"\"\"\n",
    "rdd = spark.sparkContext.parallelize([('1', 'a'), ('2', 'b'), ('3', 'c'), ('4', 'd'), ('5', 'e'), ('6', 'f')])\n",
    "schema = StructType([StructField('ID', StringType(), True), StructField('letter', StringType(), True)])\n",
    "\n",
    "result_df = create_dataframe(spark, rdd, schema)\n",
    "assert result_df.schema == schema\n",
    "assert result_df.rdd.collect() == rdd.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ffa463e480a3796dc6840dade77c29d2",
     "grade": false,
     "grade_id": "cell-90f8ab4ce25e6789",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Let's generate a Dataframe of the students tables for the incoming questions, using our newly created `create_dataframe` function. We also create temporary views for those DataFrames so we can interact with them in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "576a688e54e8d23077804e3088373859",
     "grade": false,
     "grade_id": "cell-585b7ef68a2def27",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "genders_rdd = spark.sparkContext.parallelize([('1', 'M'), ('2', 'M'), ('3', 'F'), ('4', 'F'), ('5', 'F'), ('6', 'M')])\n",
    "grades_rdd = spark.sparkContext.parallelize([('1', 5), ('2', 12), ('3', 7), ('4', 18), ('5', 9), ('6', 5)])\n",
    "\n",
    "genders_schema = StructType([StructField('ID', StringType(), True), StructField('gender', StringType(), True)])\n",
    "grades_schema = StructType([StructField('ID', StringType(), True), StructField('grade', StringType(), True)])\n",
    "\n",
    "genders_df = create_dataframe(spark, genders_rdd, genders_schema)\n",
    "grades_df = create_dataframe(spark, grades_rdd, grades_schema)\n",
    "\n",
    "genders_df.createOrReplaceTempView('genders')\n",
    "grades_df.createOrReplaceTempView('grades')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43a31e2b3f52f535ebb0dc33f5d4600f",
     "grade": false,
     "grade_id": "cell-ed61ff691a07f8cd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "You have two ways of interacting with a Dataframe :\n",
    "\n",
    "* DataFrames provide a domain-specific language for structured manipulation :\n",
    "\n",
    "```python\n",
    ">> genders_df.filter(genders_df['ID'] > 2)\n",
    "+---+------+\n",
    "| ID|gender|\n",
    "+---+------+\n",
    "|  3|     F|\n",
    "|  4|     F|\n",
    "|  5|     F|\n",
    "|  6|     M|\n",
    "+---+------+\n",
    "```\n",
    "\n",
    "In the more simple cases, you can interact with DataFrames with a syntax close to the Pandas syntax.\n",
    "\n",
    "```python\n",
    ">> genders_df[genders_df['ID'] > 2]\n",
    "+---+------+\n",
    "| ID|gender|\n",
    "+---+------+\n",
    "|  3|     F|\n",
    "|  4|     F|\n",
    "|  5|     F|\n",
    "|  6|     M|\n",
    "+---+------+\n",
    "```\n",
    "\n",
    "* The `sql` function of a SparkSession enables to run SQL queries directly on the frame and returns a DataFrame, on which you can continue your computations\n",
    "\n",
    "```python\n",
    "# Register the DataFrame as a SQL temporary view beforehand\n",
    ">> genders_df.createOrReplaceTempView('genders')\n",
    ">> spark.sql('SELECT * FROM genders WHERE ID > 2').show()\n",
    "+---+------+\n",
    "| ID|gender|\n",
    "+---+------+\n",
    "|  3|     F|\n",
    "|  4|     F|\n",
    "|  5|     F|\n",
    "|  6|     M|\n",
    "+---+------+\n",
    "```\n",
    "\n",
    "Don't hesitate to check the [DataFrame Function Reference](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions) for all of the operators you can use on a DataFrame. Use the following cell to experiment :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| ID|gender|\n",
      "+---+------+\n",
      "|  3|     F|\n",
      "|  4|     F|\n",
      "|  5|     F|\n",
      "|  6|     M|\n",
      "+---+------+\n",
      "\n",
      "None\n",
      "+---+------+\n",
      "| ID|gender|\n",
      "+---+------+\n",
      "|  3|     F|\n",
      "|  4|     F|\n",
      "|  5|     F|\n",
      "|  6|     M|\n",
      "+---+------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Use this cell to practice your new SQL skills\n",
    "print(genders_df[genders_df['ID'] > 2].show())\n",
    "print(spark.sql(\"SELECT * FROM genders AS g WHERE g.ID > 2\").show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84dda8fca16bc681158a766f5c04a039",
     "grade": false,
     "grade_id": "cell-394f3276e415e799",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Question\n",
    "\n",
    "Remember the mean grade per gender question from last assignment ? Remember how unpleasant it was ? Let's do that directly in SparkSQL ! You can do it with whatever way pleases you between programmatic SQL or SparkSQL DSL. \n",
    "\n",
    "PS : if you are using programmatic SQL interaction, you may want to define a temporary view of temporary variables. You may want to delete those views at the end of your function with `spark.catalog.dropTempView('your_view')`. Be careful if removing the view, DataFrame are also lazily computed so don't delete your view if you still have not computed and cached the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|gender|        avg(grade)|\n",
      "+------+------------------+\n",
      "|     F|11.333333333333334|\n",
      "|     M| 7.333333333333333|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using spark sql dsl\n",
    "genders_df.join(grades_df, \"ID\", \"inner\").withColumn(\"grade\", grades_df[\"grade\"].cast(\"double\")).groupby(\"gender\").avg(\"grade\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8eac7b815cee4266095f8e25ba25bba3",
     "grade": false,
     "grade_id": "cell-f3ba785bb228f244",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def mean_grade_per_gender(spark, genders_df, grades_df):\n",
    "    \"\"\"\n",
    "    Given a RDD of studentID to grades and studentID to gender, compute mean grade for each gender returned as paired RDD.\n",
    "    Assume all studentIDs are present in both RDDs, making inner join possible, no need to check that.\n",
    "    Schema of output dataframe should bee gender, mean.\n",
    "    \"\"\"\n",
    "    genders_df.createOrReplaceTempView('genders')\n",
    "    grades_df.createOrReplaceTempView('grades')\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT ge.gender, AVG(gr.grade) AS mean\n",
    "    FROM grades AS gr\n",
    "    INNER JOIN genders AS ge\n",
    "    ON gr.ID = ge.ID\n",
    "    GROUP BY ge.gender\n",
    "    \"\"\"\n",
    "\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d57dca4e3d70a2debb12ad977a4b9a98",
     "grade": true,
     "grade_id": "cell-a3fc7ed7c358193e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "3 points\n",
    "\"\"\"\n",
    "result_df = mean_grade_per_gender(spark, genders_df, grades_df).toPandas()\n",
    "result_df.columns == ['gender', 'grade']\n",
    "\n",
    "assert result_df[result_df['gender'] == 'F'].values[0][1] - 11.3 < 0.1\n",
    "assert result_df[result_df['gender'] == 'M'].values[0][1] - 7.3 < 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3ef06f8572566429eeb2d72a1ab47a3",
     "grade": false,
     "grade_id": "cell-f7f70906407004f6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Part B - Descriptive statistics in SparkSQL\n",
    "\n",
    "Let's reload the `FL_insurance_sample.csv` file from last assignment and freely interact with it.\n",
    "\n",
    "# Question\n",
    "\n",
    "Load the file by giving a path to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- policyID: string (nullable = true)\n",
      " |-- statecode: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- eq_site_limit: string (nullable = true)\n",
      " |-- hu_site_limit: string (nullable = true)\n",
      " |-- fl_site_limit: string (nullable = true)\n",
      " |-- fr_site_limit: string (nullable = true)\n",
      " |-- tiv_2011: string (nullable = true)\n",
      " |-- tiv_2012: string (nullable = true)\n",
      " |-- eq_site_deductible: string (nullable = true)\n",
      " |-- hu_site_deductible: string (nullable = true)\n",
      " |-- fl_site_deductible: string (nullable = true)\n",
      " |-- fr_site_deductible: string (nullable = true)\n",
      " |-- point_latitude: string (nullable = true)\n",
      " |-- point_longitude: string (nullable = true)\n",
      " |-- line: string (nullable = true)\n",
      " |-- construction: string (nullable = true)\n",
      " |-- point_granularity: string (nullable = true)\n",
      "\n",
      "None\n",
      "+--------+---------+-----------+-------------+-------------+-------------+-------------+---------+----------+------------------+------------------+------------------+------------------+--------------+---------------+-----------+------------+-----------------+\n",
      "|policyID|statecode|     county|eq_site_limit|hu_site_limit|fl_site_limit|fr_site_limit| tiv_2011|  tiv_2012|eq_site_deductible|hu_site_deductible|fl_site_deductible|fr_site_deductible|point_latitude|point_longitude|       line|construction|point_granularity|\n",
      "+--------+---------+-----------+-------------+-------------+-------------+-------------+---------+----------+------------------+------------------+------------------+------------------+--------------+---------------+-----------+------------+-----------------+\n",
      "|  119736|       FL|CLAY COUNTY|       498960|       498960|       498960|       498960|   498960|  792148.9|                 0|            9979.2|                 0|                 0|     30.102261|     -81.711777|Residential|     Masonry|                1|\n",
      "|  448094|       FL|CLAY COUNTY|    1322376.3|    1322376.3|    1322376.3|    1322376.3|1322376.3|1438163.57|                 0|                 0|                 0|                 0|     30.063936|     -81.707664|Residential|     Masonry|                3|\n",
      "|  206893|       FL|CLAY COUNTY|     190724.4|     190724.4|     190724.4|     190724.4| 190724.4| 192476.78|                 0|                 0|                 0|                 0|     30.089579|     -81.700455|Residential|        Wood|                1|\n",
      "|  333743|       FL|CLAY COUNTY|            0|     79520.76|            0|            0| 79520.76|  86854.48|                 0|                 0|                 0|                 0|     30.063236|     -81.707703|Residential|        Wood|                3|\n",
      "|  172534|       FL|CLAY COUNTY|            0|     254281.5|            0|     254281.5| 254281.5| 246144.49|                 0|                 0|                 0|                 0|     30.060614|     -81.702675|Residential|        Wood|                1|\n",
      "+--------+---------+-----------+-------------+-------------+-------------+-------------+---------+----------+------------------+------------------+------------------+------------------+--------------+---------------+-----------+------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "+-------+------------------+---------+-----------------+-----------------+------------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-----------+------------+------------------+\n",
      "|summary|          policyID|statecode|           county|    eq_site_limit|     hu_site_limit|    fl_site_limit|    fr_site_limit|         tiv_2011|          tiv_2012|eq_site_deductible|hu_site_deductible|fl_site_deductible|fr_site_deductible|     point_latitude|   point_longitude|       line|construction| point_granularity|\n",
      "+-------+------------------+---------+-----------------+-----------------+------------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-----------+------------+------------------+\n",
      "|  count|             10000|    10000|            10000|            10000|             10000|            10000|            10000|            10000|             10000|             10000|             10000|             10000|             10000|              10000|             10000|      10000|       10000|             10000|\n",
      "|   mean|       550265.0944|     null|             null|491346.8835300008|1265577.2590670001|475505.7955200003| 608800.192110001|   1329638.613291|1597856.6213139917|2218.9652099999994| 5908.962239999955|249.97220999999996|             1.035| 30.184539691699772|-83.65557127759976|       null|        null|             1.776|\n",
      "| stddev|262721.11513752834|     null|             null|6012340.391628529| 7501844.826689992|6029818.026724503|6152749.885724536|8067572.074524733| 9988316.225920735| 87464.19674104493| 95051.28845014247| 9218.616190410517| 35.13263732230355|0.46123301984315285| 2.319959962990047|       null|        null|1.1655727587695222|\n",
      "|    min|            100141|       FL|   ALACHUA COUNTY|                0|                 0|                0|                0|        1000158.3|           1000.99|                 0|                 0|                 0|                 0|          28.478875|         -80.86231| Commercial|     Masonry|                 1|\n",
      "|    25%|          323610.0|     null|             null|              0.0|           15570.0|              0.0|              0.0|         17358.21|           20516.2|               0.0|               0.0|               0.0|               0.0|           29.97043|        -86.358915|       null|        null|               1.0|\n",
      "|    50%|          548600.0|     null|             null|              0.0|         106339.72|              0.0|              0.0|        111841.54|          132531.5|               0.0|               0.0|               0.0|               0.0|          30.306383|         -82.44461|       null|        null|               1.0|\n",
      "|    75%|          779686.0|     null|             null|          11246.4|          575865.0|           5094.0|          31404.6|        594126.51|         711020.59|               0.0|               0.0|               0.0|               0.0|           30.47011|        -81.591133|       null|        null|               3.0|\n",
      "|    max|            999971|       FL|WASHINGTON COUNTY|            99918|         999616.68|            99918|            99918|        999616.68|         999963.27|             99900|             99900|             955.8|               900|           30.98982|         -87.44729|Residential|        Wood|                 4|\n",
      "+-------+------------------+---------+-----------------+-----------------+------------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-----------+------------+------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "filePath = 'FL_insurance_sample.csv'\n",
    "# filePath = 'pyspark/2-novice/FL_insurance_sample.csv'\n",
    "df = spark.read.option(\"header\", True).csv(filePath)\n",
    "\n",
    "print(df.printSchema())\n",
    "print(df.show(5))\n",
    "print(df.summary().show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a8aaf77691064a2f0709ea674097c9d",
     "grade": false,
     "grade_id": "cell-499cfd4c4ed40d81",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def read_csv(spark, path):\n",
    "    \"\"\"\n",
    "    Create a DataFrame by loading an external csv file. We don't expect any formatting nor processing here. \n",
    "    We assume the file has a header, uses \" as double quote and , as delimiter. Infer its schema automatically.\n",
    "    You don't need to raise an exception if the file does not exist.    \n",
    "    \"\"\"\n",
    "    return spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a1eb9c16951a70094e2eb14164e8391",
     "grade": true,
     "grade_id": "cell-00468b3f4490d43b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "2 points\n",
    "\"\"\"\n",
    "file_path = filePath\n",
    "result_df = read_csv(spark, file_path)\n",
    "\n",
    "assert result_df.schema == StructType([\n",
    "    StructField('policyID',IntegerType(),True),\n",
    "    StructField('statecode',StringType(),True),\n",
    "    StructField('county',StringType(),True),\n",
    "    StructField('eq_site_limit',DoubleType(),True),\n",
    "    StructField('hu_site_limit',DoubleType(),True),\n",
    "    StructField('fl_site_limit',DoubleType(),True),\n",
    "    StructField('fr_site_limit',DoubleType(),True),\n",
    "    StructField('tiv_2011',DoubleType(),True),\n",
    "    StructField('tiv_2012',DoubleType(),True),\n",
    "    StructField('eq_site_deductible',DoubleType(),True),\n",
    "    StructField('hu_site_deductible',DoubleType(),True),\n",
    "    StructField('fl_site_deductible',DoubleType(),True),\n",
    "    StructField('fr_site_deductible',IntegerType(),True),\n",
    "    StructField('point_latitude',DoubleType(),True),\n",
    "    StructField('point_longitude',DoubleType(),True),\n",
    "    StructField('line',StringType(),True),\n",
    "    StructField('construction',StringType(),True),\n",
    "    StructField('point_granularity',IntegerType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53dae314d93d79d671059f9407a2c514",
     "grade": false,
     "grade_id": "cell-268bf2c0c12204ae",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Question\n",
    "\n",
    "Let's plot the number of different counties in a histogram, like in the previous assignment. We have imported the `bokeh` module for interactive plotting. To do that, return a Pandas a dataframe which contains, for each county, the number of its occurences in the dataset.\n",
    "\n",
    "_Hint: a Spark Dataframe is distributed on a number of workers, so it cannot be plotted as is. You will need to collect the data you want to plot back in the driver. The `toPandas` is usable to retrieve a Pandas local Dataframe, be careful to only use it on small Dataframes !_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0afd6a03f49cb00d9acc6369d8cadc3a",
     "grade": false,
     "grade_id": "cell-25e140d92c569470",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|           county|count|\n",
      "+-----------------+-----+\n",
      "|     DUVAL COUNTY| 1894|\n",
      "|  OKALOOSA COUNTY| 1115|\n",
      "|SANTA ROSA COUNTY|  856|\n",
      "|   VOLUSIA COUNTY|  833|\n",
      "| ST  JOHNS COUNTY|  657|\n",
      "|   ALACHUA COUNTY|  614|\n",
      "|  ESCAMBIA COUNTY|  494|\n",
      "|       BAY COUNTY|  403|\n",
      "|      CLAY COUNTY|  346|\n",
      "|    WALTON COUNTY|  288|\n",
      "|      LEON COUNTY|  246|\n",
      "|    PUTNAM COUNTY|  245|\n",
      "|   JACKSON COUNTY|  208|\n",
      "|   FLAGLER COUNTY|  204|\n",
      "|   GADSDEN COUNTY|  196|\n",
      "|  SUWANNEE COUNTY|  154|\n",
      "|    NASSAU COUNTY|  135|\n",
      "|  COLUMBIA COUNTY|  124|\n",
      "|WASHINGTON COUNTY|  116|\n",
      "|    TAYLOR COUNTY|  113|\n",
      "+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insurance_df = read_csv(spark, file_path)\n",
    "insurance_df.createOrReplaceTempView('insurance')\n",
    "insurance_df.groupby(\"county\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ae528e9603872cb6514fb54fe5492e4",
     "grade": false,
     "grade_id": "cell-ef312f5810eb4820",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def count_county(spark, insurance_df):\n",
    "    \"\"\"\n",
    "    Return a Pandas a dataframe which contains, for each county, the number of its occurences in the dataset. \n",
    "    Schema of the Dataframe should be ['county', 'count']    \n",
    "    \"\"\"\n",
    "    return insurance_df.groupby(\"county\").count().orderBy(\"count\", ascending=False).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f830073770b813cebfeefedda91abb9f",
     "grade": true,
     "grade_id": "cell-763e162bf7d285f6",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "3 points\n",
    "\"\"\"\n",
    "df = count_county(spark, insurance_df)\n",
    "result = df.set_index('county').to_dict()['count']\n",
    "\n",
    "assert result.get('CLAY COUNTY') == 346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a7a5ff2274c9522c799cf3f1698171e",
     "grade": false,
     "grade_id": "cell-1e506728a67966a5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "\n\n\n\n\n\n  <div class=\"bk-root\" id=\"91dcc46c-a7ee-41d0-b704-ca0e65575a57\" data-root-id=\"1005\"></div>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n    \n  var docs_json = {\"e6c3c479-72b8-4dbd-883e-5a4c26d7a003\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1016\"}],\"center\":[{\"id\":\"1018\"},{\"id\":\"1022\"}],\"left\":[{\"id\":\"1019\"}],\"plot_height\":250,\"renderers\":[{\"id\":\"1028\"}],\"title\":{\"id\":\"1006\"},\"toolbar\":{\"id\":\"1023\"},\"x_range\":{\"id\":\"1008\"},\"x_scale\":{\"id\":\"1012\"},\"y_range\":{\"id\":\"1010\"},\"y_scale\":{\"id\":\"1014\"}},\"id\":\"1005\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"count\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"county\"}},\"id\":\"1026\",\"type\":\"VBar\"},{\"attributes\":{\"text\":\"County counts\"},\"id\":\"1006\",\"type\":\"Title\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1004\"}]},\"id\":\"1023\",\"type\":\"Toolbar\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"count\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"county\"}},\"id\":\"1027\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"1036\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1033\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"formatter\":{\"id\":\"1033\"},\"ticker\":{\"id\":\"1017\"}},\"id\":\"1016\",\"type\":\"CategoricalAxis\"},{\"attributes\":{\"data_source\":{\"id\":\"1003\"},\"glyph\":{\"id\":\"1026\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1027\"},\"selection_glyph\":null,\"view\":{\"id\":\"1029\"}},\"id\":\"1028\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1017\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"formatter\":{\"id\":\"1031\"},\"ticker\":{\"id\":\"1020\"}},\"id\":\"1019\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1031\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"axis\":{\"id\":\"1016\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"1018\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"LinearScale\"},{\"attributes\":{\"factors\":[\"DUVAL COUNTY\",\"OKALOOSA COUNTY\",\"SANTA ROSA COUNTY\",\"VOLUSIA COUNTY\",\"ST  JOHNS COUNTY\",\"ALACHUA COUNTY\",\"ESCAMBIA COUNTY\",\"BAY COUNTY\",\"CLAY COUNTY\",\"WALTON COUNTY\",\"LEON COUNTY\",\"PUTNAM COUNTY\",\"JACKSON COUNTY\",\"FLAGLER COUNTY\",\"GADSDEN COUNTY\",\"SUWANNEE COUNTY\",\"NASSAU COUNTY\",\"COLUMBIA COUNTY\",\"WASHINGTON COUNTY\",\"TAYLOR COUNTY\",\"WAKULLA COUNTY\",\"MADISON COUNTY\",\"GULF COUNTY\",\"BAKER COUNTY\",\"CALHOUN COUNTY\",\"LAFAYETTE COUNTY\",\"JEFFERSON COUNTY\",\"MARION COUNTY\",\"HOLMES COUNTY\",\"FRANKLIN COUNTY\",\"LIBERTY COUNTY\",\"HAMILTON COUNTY\",\"BRADFORD COUNTY\",\"LAKE COUNTY\",\"SUMTER COUNTY\",\"UNION COUNTY\"]},\"id\":\"1008\",\"type\":\"FactorRange\"},{\"attributes\":{},\"id\":\"1020\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis\":{\"id\":\"1019\"},\"dimension\":1,\"ticker\":null},\"id\":\"1022\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"1003\"}},\"id\":\"1029\",\"type\":\"CDSView\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"type\",\"@county\"],[\"count\",\"@count\"]]},\"id\":\"1004\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1035\",\"type\":\"Selection\"},{\"attributes\":{\"start\":0},\"id\":\"1010\",\"type\":\"DataRange1d\"},{\"attributes\":{\"data\":{\"count\":[1894,1115,856,833,657,614,494,403,346,288,246,245,208,204,196,154,135,124,116,113,85,81,72,70,68,68,57,50,40,37,36,35,29,14,9,8],\"county\":[\"DUVAL COUNTY\",\"OKALOOSA COUNTY\",\"SANTA ROSA COUNTY\",\"VOLUSIA COUNTY\",\"ST  JOHNS COUNTY\",\"ALACHUA COUNTY\",\"ESCAMBIA COUNTY\",\"BAY COUNTY\",\"CLAY COUNTY\",\"WALTON COUNTY\",\"LEON COUNTY\",\"PUTNAM COUNTY\",\"JACKSON COUNTY\",\"FLAGLER COUNTY\",\"GADSDEN COUNTY\",\"SUWANNEE COUNTY\",\"NASSAU COUNTY\",\"COLUMBIA COUNTY\",\"WASHINGTON COUNTY\",\"TAYLOR COUNTY\",\"WAKULLA COUNTY\",\"MADISON COUNTY\",\"GULF COUNTY\",\"BAKER COUNTY\",\"CALHOUN COUNTY\",\"LAFAYETTE COUNTY\",\"JEFFERSON COUNTY\",\"MARION COUNTY\",\"HOLMES COUNTY\",\"FRANKLIN COUNTY\",\"LIBERTY COUNTY\",\"HAMILTON COUNTY\",\"BRADFORD COUNTY\",\"LAKE COUNTY\",\"SUMTER COUNTY\",\"UNION COUNTY\"],\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35]},\"selected\":{\"id\":\"1035\"},\"selection_policy\":{\"id\":\"1036\"}},\"id\":\"1003\",\"type\":\"ColumnDataSource\"}],\"root_ids\":[\"1005\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n  var render_items = [{\"docid\":\"e6c3c479-72b8-4dbd-883e-5a4c26d7a003\",\"root_ids\":[\"1005\"],\"roots\":{\"1005\":\"91dcc46c-a7ee-41d0-b704-ca0e65575a57\"}}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    var attempts = 0;\n    var timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1005"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot it for fun with bokeh.\n",
    "data = count_county(spark, insurance_df)\n",
    "\n",
    "source = ColumnDataSource(data)\n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"type\", \"@county\"),\n",
    "    (\"count\", \"@count\"),\n",
    "])\n",
    "\n",
    "p = figure(x_range=data['county'].values, plot_height=250, title=\"County counts\", tools=[hover])\n",
    "\n",
    "p.vbar(x='county', top='count', width=0.9, source=source)\n",
    "\n",
    "p.xgrid.grid_line_color = None\n",
    "p.y_range.start = 0\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6cad25978528231cd59c728826d7adc0",
     "grade": false,
     "grade_id": "cell-7bfa0111bdc89374",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Postrequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f7237812e59b81cf93e7371b836c222",
     "grade": false,
     "grade_id": "cell-d620c45785d3135d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}